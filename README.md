# NavAI - Reimagining Navigation Through AR

[![MLH Winner](https://img.shields.io/badge/MLH%20Winner-Best%20Use%20of%20Gemini%20AI-F7302F?style=for-the-badge&logo=mlh&logoColor=white)](https://mlh.io)
[![Gemini AI](https://img.shields.io/badge/Powered%20by-Gemini%20AI-1A73E8?style=for-the-badge&logo=google&logoColor=white)](https://deepmind.google/technologies/gemini/)
[![Spectacles](https://img.shields.io/badge/Spectacles-Light%20Gray?color=FFFC00&logo=snapchat&logoColor=white)](https://spectacles.com)
[![TypeScript](https://img.shields.io/badge/TypeScript-Light%20Gray?color=3178C6&logo=typescript&logoColor=white)](https://www.typescriptlang.org/)
[![Snap AR](https://img.shields.io/badge/Snap%20AR-Light%20Gray?color=000000&logo=snapchat&logoColor=white)](https://ar.snap.com/)

> ğŸ† **Winner of "Best Use of Gemini AI" at ImmerseGT 2024** - Georgia Tech's Premier VR/XR Hackathon

An AR-powered navigation platform that transforms urban exploration through natural voice commands, dynamic AR mapping, and AI-generated insights. Using Snap Spectacles and Gemini AI, NavAI delivers a hands-free, immersive wayfinding experience for modern explorers.

<a href="https://ibb.co/sd1nPwHx"><img src="./Outdoor Navigation/README-ref/sample-list-outdoor-navigation-rounded-edges.gif" alt="AR Navigation Demo" width="500" /></a>

---

## Table of Contents

- [Overview](#overview)
- [Tech Stack](#tech-stack)
- [Directory Structure](#directory-structure)
- [Modules and Functions](#modules-and-functions)
  - [Voice Interaction & Gemini AI](#voice-interaction--gemini-ai)
  - [Dynamic AR Mapping](#dynamic-ar-mapping)
  - [Snapshot Analysis](#snapshot-analysis)
- [Usage](#usage)
- [License](#license)

---

## Overview

NavAI reimagines navigation by integrating immersive AR with AI-driven natural language understanding and image analysis. With voice-activated queries and real-time AR map overlays, users can effortlessly discover points of interest and obtain contextual informationâ€”all without ever pulling out their phone.

---

## Tech Stack

### Hardware
> **Snap Spectacles** â€” AR-enabled smart glasses  
> **Built-in Camera & Mic** â€” For seamless image capture and voice input  
> **Location Sensors** â€” Precise geolocation for dynamic mapping

### Core Technologies
> **TypeScript** â€” Strongly-typed development environment  
> **Snap AR SDK** â€” AR content rendering and spatial tracking  
> **SIK (Spectacles Interaction Kit)** â€” Gesture recognition and interaction

### AI & APIs
> **Google Gemini AI** â€” Natural language processing and visual analysis  
> **Google Places API** â€” Dynamic retrieval of nearby points of interest  
> **Custom Flask Backend** â€” Image processing and AI integration

---

## Directory Structure

```
/Outdoor Navigation
â”œâ”€â”€ Assets/                      # Main project assets and code
â”‚   â”œâ”€â”€ VoiceController.ts      # Voice command processing
â”‚   â”œâ”€â”€ SpeechToText.ts         # Speech recognition integration
â”‚   â”œâ”€â”€ Scripts/                # Core TypeScript/JavaScript files
â”‚   â”‚   â”œâ”€â”€ geminiHandler.ts    # Gemini AI integration
â”‚   â”‚   â”œâ”€â”€ PlacesWrapper.ts    # Places API wrapper
â”‚   â”‚   â”œâ”€â”€ MapUIController.ts  # Map interface controls
â”‚   â”‚   â”œâ”€â”€ MapManipulation.ts  # Map interaction handling
â”‚   â”‚   â”œâ”€â”€ MapConstants.ts     # Configuration constants
â”‚   â”‚   â”œâ”€â”€ NorthIndicator.ts   # Compass functionality
â”‚   â”‚   â”œâ”€â”€ PinchController.ts  # Gesture recognition
â”‚   â”‚   â”œâ”€â”€ PopupController.ts  # Information display
â”‚   â”‚   â”œâ”€â”€ QuestMarkController.ts  # Navigation markers
â”‚   â”‚   â”œâ”€â”€ UICollisionDetector.ts  # UI interaction handling
â”‚   â”‚   â”œâ”€â”€ MapMessageController.ts  # Map messaging system
â”‚   â”‚   â”œâ”€â”€ MapContainerController.ts # Map container management
â”‚   â”‚   â””â”€â”€ Logging.ts          # Logging utilities
â”‚   â”œâ”€â”€ MapComponent/           # Map visualization system
â”‚   â”‚   â”œâ”€â”€ Scripts/           # Map-specific scripts
â”‚   â”‚   â”œâ”€â”€ Prefabs/           # Reusable map elements
â”‚   â”‚   â”œâ”€â”€ Materials/         # Map styling assets
â”‚   â”‚   â””â”€â”€ Textures/          # Map visual resources
â”‚   â”œâ”€â”€ SpectaclesInteractionKit/  # SIK integration
â”‚   â”œâ”€â”€ Device Camera Texture   # Camera input handling
â”‚   â”œâ”€â”€ VoiceInput             # Voice input configuration
â”‚   â””â”€â”€ SoundOutput            # Audio output handling
â”œâ”€â”€ Support/                    # Project support files
â”œâ”€â”€ Workspaces/                # Lens Studio workspace configs
â”œâ”€â”€ README-ref/                # Documentation assets
â”œâ”€â”€ tsconfig.json              # TypeScript configuration
â””â”€â”€ OutdoorNavigation.esproj   # Project configuration file
```

### Key Components

- **Voice Processing**: `VoiceController.ts` and `SpeechToText.ts` handle wake word detection ("Hey Alice") and voice commands
- **Map System**: Multiple controllers (`MapUIController`, `MapManipulation`, etc.) manage the AR map experience
- **AI Integration**: `geminiHandler.ts` coordinates between Gemini AI and the system, while `PlacesWrapper.ts` handles Places API interactions
- **Interaction**: `PinchController.ts` and `PopupController.ts` manage user input and feedback
- **Supporting Systems**: Includes camera, voice input, and sound output configurations

The project follows a modular architecture, separating concerns between voice processing, map visualization, AI integration, and user interaction. This structure enables easy maintenance and future enhancements of individual components.

---

## Modules and Functions

### Voice Interaction & Gemini AI

- **Purpose:** Interprets natural language queries (e.g., "Find me a quiet coffee shop") via voice commands.
- **Functionality:** Uses Gemini AI to map user intent to relevant location categories, generating structured requests for the Places API.

### Dynamic AR Mapping

- **Purpose:** Renders a real-time, interactive AR map overlay displaying nearby points of interest.
- **Functionality:** Updates map pins dynamically as the user moves, ensuring location-aware navigation.

### Snapshot Analysis

- **Purpose:** Captures and processes visual data using simple gesture controls.
- **Functionality:** Uses a pinch gesture to capture surroundings and leverages OCR and AI to generate rich, contextual descriptions of buildings or landmarks.

---

## Usage

1. **Activate Voice Command:** Say the trigger phrase (e.g., "Hey Alice") and ask for your desired location.
2. **Explore AR Map:** Watch as dynamic location pins appear over your real-world view.
3. **Capture Insights:** Use a pinch gesture to capture a scene and receive immediate AI-generated insights.

---

## License

This project is licensed under the [MIT License](license.txt).
